13984932_1
--dataset=hiv --runseed=1 --eval_train --batch_size=256 --dropout_ratio=0.5 --input_model_file=../output/3D_hybrid_02_masking/GEOM_3D_nmol50000_nconf5_nupper1000/CL_1_VAE_1/6_51_10_0.1/0.15_EBM_dot_prod_0.2_normalize_l2_detach_target_2_100_0/pretraining_model.pth
start
arguments	 Namespace(AE_loss='l2', AE_model='AE', CL_neg_samples=1, CL_similarity_metric='InfoNCE_dot_prod', JK='last', SSL_2D_mode='AM', SSL_masking_ratio=0, T=0.1, alpha_1=1, alpha_2=1, alpha_3=0.1, batch_size=256, beta=1, contextpred_neg_samples=1, csize=3, cutoff=10, data_dir_chirality='../datasets/chirality/d4_docking/d4_docking_rs.csv', dataset='hiv', decay=0, detach_target=True, device=0, dropout_ratio=0.5, emb_dim=300, engg_n_layers=4, epochs=100, eval_train=True, flow_length=8, flow_model='planar', gamma_joao=0.1, gamma_joaov2=0.1, gnn_lr_scale=1, gnn_type='gin', graph_pooling='mean', input_data_dir='', input_model_file='../output/3D_hybrid_02_masking/GEOM_3D_nmol50000_nconf5_nupper1000/CL_1_VAE_1/6_51_10_0.1/0.15_EBM_dot_prod_0.2_normalize_l2_detach_target_2_100_0/pretraining_model.pth', iw_samples=5, lr=0.001, lr_scale=1, m_dim=50, mask_edge=0, mask_rate=0.15, model_3d='schnet', normalize=False, num_filters=128, num_gaussians=51, num_interactions=6, num_layer=5, num_workers=8, output_model_dir='', readout='mean', runseed=1, schnet_lr_scale=1, se3_transformer_div=2, se3_transformer_n_heads=8, se3_transformer_num_channels=32, se3_transformer_num_degrees=4, se3_transformer_num_layers=7, se3_transformer_num_nlayers=1, seed=42, spherenet_basis_emb_size_angle=8, spherenet_basis_emb_size_dist=8, spherenet_basis_emb_size_torsion=8, spherenet_cutoff=3.0, spherenet_envelope_exponent=5, spherenet_int_emb_size=64, spherenet_num_after_skip=2, spherenet_num_before_skip=1, spherenet_num_layers=4, spherenet_num_output_layers=3, spherenet_num_radial=6, spherenet_num_spherical=3, spherenet_out_emb_channels=256, split='scaffold', split_path='../datasets/chirality/d4_docking/rs/split0.npy', verbose=False)
Dataset: hiv
Data: Data(edge_attr=[2259376, 2], edge_index=[2, 2259376], id=[41127], x=[1049163, 2], y=[41127])
MoleculeDataset(41127)
split via scaffold
Data(edge_attr=[32, 2], edge_index=[2, 32], id=[1], x=[16, 2], y=[1])
GNN_graphpred(
(molecule_model): GNN(
(x_embedding1): Embedding(120, 300)
(x_embedding2): Embedding(3, 300)
(gnns): ModuleList(
(0): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(1): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(2): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(3): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(4): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
)
(batch_norms): ModuleList(
(0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
)
(graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.25784578002187203
train: 0.768889	val: 0.720511	test: 0.705614
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 2
Loss: 0.1374681497799406
train: 0.792761	val: 0.763277	test: 0.746055
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 3
Loss: 0.13279073437497982
train: 0.808620	val: 0.786262	test: 0.730155
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 4
Loss: 0.12862093549530856
train: 0.810778	val: 0.749887	test: 0.746513
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 5
Loss: 0.12626715842963013
train: 0.830653	val: 0.792126	test: 0.746683
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 6
Loss: 0.1228776700961627
train: 0.836397	val: 0.794716	test: 0.753193
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 7
Loss: 0.1215807507035518
train: 0.835145	val: 0.814408	test: 0.710039
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 8
Loss: 0.12033235459764366
train: 0.848089	val: 0.801921	test: 0.761581
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 9
Loss: 0.11878661996341414
train: 0.850102	val: 0.807904	test: 0.768002
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 10
Loss: 0.11902332602314743
train: 0.849819	val: 0.789300	test: 0.757406
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 11
Loss: 0.11820061268258023
train: 0.858144	val: 0.810847	test: 0.746098
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 12
Loss: 0.11594224002658976
train: 0.857474	val: 0.803596	test: 0.760559
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 13
Loss: 0.11457462620549298
train: 0.864473	val: 0.796235	test: 0.769947
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 14
Loss: 0.11326509815154605
train: 0.863148	val: 0.779364	test: 0.746946
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 15
Loss: 0.11310856550804949
train: 0.870055	val: 0.804383	test: 0.774775
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 16
Loss: 0.11141406132382012
train: 0.879048	val: 0.797702	test: 0.756971
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 17
Loss: 0.11055809287051721
train: 0.874957	val: 0.828067	test: 0.749814
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 18
Loss: 0.11082987120616643
train: 0.878948	val: 0.828719	test: 0.734676
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 19
Loss: 0.10915083273013204
train: 0.885891	val: 0.798066	test: 0.758020
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 20
Loss: 0.10779580457800847
train: 0.888216	val: 0.812463	test: 0.742123
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 21
Loss: 0.10869373386262997
train: 0.894401	val: 0.813241	test: 0.758883
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 22
Loss: 0.10803690996002503
train: 0.883429	val: 0.804888	test: 0.760038
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 23
Loss: 0.10750754573352808
train: 0.897621	val: 0.818955	test: 0.764864
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 24
Loss: 0.10596556723389272
train: 0.899246	val: 0.828609	test: 0.763779
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 25
Loss: 0.10663955973894126
train: 0.899193	val: 0.820265	test: 0.747498
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 26
Loss: 0.1036974959689367
train: 0.902642	val: 0.801593	test: 0.768476
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 27
Loss: 0.104062857129735
train: 0.906477	val: 0.805779	test: 0.752282
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 28
Loss: 0.10503912283383181
train: 0.895707	val: 0.772922	test: 0.721066
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 29
Loss: 0.10353043783764058
train: 0.898133	val: 0.815559	test: 0.747890
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 30
Loss: 0.1031634703032394
train: 0.914408	val: 0.805678	test: 0.772680
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 31
Loss: 0.1015554669770108
train: 0.910337	val: 0.808740	test: 0.772742
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 32
Loss: 0.10114420607246632
train: 0.911755	val: 0.804818	test: 0.753842
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 33
Loss: 0.10225034303584316
train: 0.916056	val: 0.818109	test: 0.747114
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 34
Loss: 0.10130045841489337
train: 0.916525	val: 0.801860	test: 0.763738
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 35
Loss: 0.10034713947530607
train: 0.921719	val: 0.819735	test: 0.766000
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 36
Loss: 0.09879963279995486
train: 0.919018	val: 0.804022	test: 0.752330
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 37
Loss: 0.09882790024230526
train: 0.919329	val: 0.789566	test: 0.770892
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 38
Loss: 0.09827864100158706
train: 0.924147	val: 0.802616	test: 0.753952
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 39
Loss: 0.09816969606050144
train: 0.930116	val: 0.800402	test: 0.754061
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 40
Loss: 0.09820812293769636
train: 0.920879	val: 0.805644	test: 0.756332
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 41
Loss: 0.0976593428718479
train: 0.924309	val: 0.804490	test: 0.774969
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 42
Loss: 0.0987530688231251
train: 0.929872	val: 0.794597	test: 0.769818
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 43
Loss: 0.09624202485401019
train: 0.929954	val: 0.812773	test: 0.765955
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 44
Loss: 0.09666926909296102
train: 0.934586	val: 0.789796	test: 0.769310
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 45
Loss: 0.09515951204901713
train: 0.928890	val: 0.788372	test: 0.745766
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 46
Loss: 0.09450034570892196
train: 0.927312	val: 0.806768	test: 0.765279
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 47
Loss: 0.09495355071556132
train: 0.931687	val: 0.765950	test: 0.769499
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 48
Loss: 0.09424043969211772
train: 0.942472	val: 0.799928	test: 0.760123
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 49
Loss: 0.09416572509971409
train: 0.943166	val: 0.788115	test: 0.758197
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 50
Loss: 0.09352020236558731
train: 0.935537	val: 0.807230	test: 0.773256
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 51
Loss: 0.09293231708083909
train: 0.942270	val: 0.781302	test: 0.756168
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 52
Loss: 0.09202323984487679
train: 0.941711	val: 0.799511	test: 0.788173
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 53
Loss: 0.09293466064530233
train: 0.946743	val: 0.796342	test: 0.757058
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 54
Loss: 0.09201438242299409
train: 0.941212	val: 0.765077	test: 0.758595
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 55
Loss: 0.09212893296707093
train: 0.946931	val: 0.795956	test: 0.767651
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 56
Loss: 0.09080688778112456
train: 0.947152	val: 0.786112	test: 0.767023
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 57
Loss: 0.08934580997582804
train: 0.945880	val: 0.778617	test: 0.731602
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 58
Loss: 0.08989914002517027
train: 0.950869	val: 0.762055	test: 0.759831
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 59
Loss: 0.09080944739663191
train: 0.950905	val: 0.788942	test: 0.754592
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 60
Loss: 0.08907042552293314
train: 0.945332	val: 0.797025	test: 0.755117
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 61
Loss: 0.0885384936834294
train: 0.952521	val: 0.785720	test: 0.754848
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 62
Loss: 0.0880777781721568
train: 0.952958	val: 0.796407	test: 0.764872
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 63
Loss: 0.08885765573606763
train: 0.954274	val: 0.791694	test: 0.756666
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 64
Loss: 0.08849335118475406
train: 0.958289	val: 0.794784	test: 0.764922
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 65
Loss: 0.08848463711019933
train: 0.955749	val: 0.788807	test: 0.752469
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 66
Loss: 0.08661945592556278
train: 0.959580	val: 0.785350	test: 0.772120
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 67
Loss: 0.08693849221322013
train: 0.957655	val: 0.775481	test: 0.767972
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 68
Loss: 0.08485774371703236
train: 0.957726	val: 0.794781	test: 0.766492
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 69
Loss: 0.08700497376149609
train: 0.961377	val: 0.792659	test: 0.777860
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 70
Loss: 0.0854345045976007
train: 0.955333	val: 0.807157	test: 0.774505
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 71
Loss: 0.08422854373078041
train: 0.960577	val: 0.775282	test: 0.748060
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 72
Loss: 0.08518834791691933
train: 0.962365	val: 0.787536	test: 0.770859
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 73
Loss: 0.08466609251692463
train: 0.959293	val: 0.791740	test: 0.778354
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 74
Loss: 0.08454944487454735
train: 0.965330	val: 0.797053	test: 0.769215
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 75
Loss: 0.08408230973242661
train: 0.964823	val: 0.769238	test: 0.765698
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 76
Loss: 0.0830342899814597
train: 0.967605	val: 0.788464	test: 0.774646
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 77
Loss: 0.08340330925552811
train: 0.960069	val: 0.797245	test: 0.760005
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 78
Loss: 0.0823898746391577
train: 0.966704	val: 0.783969	test: 0.758184
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 79
Loss: 0.08488657600872886
train: 0.963146	val: 0.783265	test: 0.746677
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 80
Loss: 0.0803950157690141
train: 0.964659	val: 0.781862	test: 0.754003
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 81
Loss: 0.08086917198012827
train: 0.966332	val: 0.783188	test: 0.753906
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 82
Loss: 0.0819037940751135
train: 0.969466	val: 0.794652	test: 0.764391
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 83
Loss: 0.08035164484409317
train: 0.970847	val: 0.801195	test: 0.759586
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 84
Loss: 0.081579094637473
train: 0.971929	val: 0.787680	test: 0.770598
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 85
Loss: 0.08110101215759156
train: 0.967123	val: 0.779110	test: 0.745055
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 86
Loss: 0.08014091802730304
train: 0.971750	val: 0.795880	test: 0.762630
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 87
Loss: 0.07916651721410405
train: 0.967569	val: 0.785344	test: 0.770807
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 88
Loss: 0.07969377508052991
train: 0.974626	val: 0.796673	test: 0.777400
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 89
Loss: 0.07725601405239652
train: 0.968129	val: 0.803648	test: 0.771852
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 90
Loss: 0.07770757275741386
train: 0.975621	val: 0.777658	test: 0.772058
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 91
Loss: 0.07870697117635514
train: 0.972320	val: 0.790886	test: 0.768310
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 92
Loss: 0.07787446636551719
train: 0.973844	val: 0.794600	test: 0.765882
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 93
Loss: 0.07764340326254977
train: 0.976065	val: 0.805650	test: 0.772132
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 94
Loss: 0.07766159957708871
train: 0.973309	val: 0.782919	test: 0.749821
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 95
Loss: 0.07846406351032324
train: 0.976623	val: 0.805228	test: 0.764393
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 96
Loss: 0.07504041372092599
train: 0.978070	val: 0.782273	test: 0.770782
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 97
Loss: 0.07615673456498356
train: 0.977808	val: 0.792392	test: 0.761987
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 98
Loss: 0.07675361543050331
train: 0.979157	val: 0.754550	test: 0.749354
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 99
Loss: 0.07566542578228119
train: 0.978363	val: 0.810574	test: 0.764596
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 100
Loss: 0.07422123770861631
train: 0.975472	val: 0.784719	test: 0.751162
acc train: 0.000000	val: 0.000000	test: 0.000000

best train: 0.878948	val: 0.828719	test: 0.734676
best ACC train: 0.000000	val: 0.000000	test: 0.000000
end
