13984932_1
--dataset=bbbp --runseed=1 --eval_train --batch_size=256 --dropout_ratio=0.5 --input_model_file=../output/3D_hybrid_02_masking/GEOM_3D_nmol50000_nconf5_nupper1000/CL_1_VAE_1/6_51_10_0.1/0.15_EBM_dot_prod_0.2_normalize_l2_detach_target_2_100_0/pretraining_model.pth
start
arguments	 Namespace(AE_loss='l2', AE_model='AE', CL_neg_samples=1, CL_similarity_metric='InfoNCE_dot_prod', JK='last', SSL_2D_mode='AM', SSL_masking_ratio=0, T=0.1, alpha_1=1, alpha_2=1, alpha_3=0.1, batch_size=256, beta=1, contextpred_neg_samples=1, csize=3, cutoff=10, data_dir_chirality='../datasets/chirality/d4_docking/d4_docking_rs.csv', dataset='bbbp', decay=0, detach_target=True, device=0, dropout_ratio=0.5, emb_dim=300, engg_n_layers=4, epochs=100, eval_train=True, flow_length=8, flow_model='planar', gamma_joao=0.1, gamma_joaov2=0.1, gnn_lr_scale=1, gnn_type='gin', graph_pooling='mean', input_data_dir='', input_model_file='../output/3D_hybrid_02_masking/GEOM_3D_nmol50000_nconf5_nupper1000/CL_1_VAE_1/6_51_10_0.1/0.15_EBM_dot_prod_0.2_normalize_l2_detach_target_2_100_0/pretraining_model.pth', iw_samples=5, lr=0.001, lr_scale=1, m_dim=50, mask_edge=0, mask_rate=0.15, model_3d='schnet', normalize=False, num_filters=128, num_gaussians=51, num_interactions=6, num_layer=5, num_workers=8, output_model_dir='', readout='mean', runseed=1, schnet_lr_scale=1, se3_transformer_div=2, se3_transformer_n_heads=8, se3_transformer_num_channels=32, se3_transformer_num_degrees=4, se3_transformer_num_layers=7, se3_transformer_num_nlayers=1, seed=42, spherenet_basis_emb_size_angle=8, spherenet_basis_emb_size_dist=8, spherenet_basis_emb_size_torsion=8, spherenet_cutoff=3.0, spherenet_envelope_exponent=5, spherenet_int_emb_size=64, spherenet_num_after_skip=2, spherenet_num_before_skip=1, spherenet_num_layers=4, spherenet_num_output_layers=3, spherenet_num_radial=6, spherenet_num_spherical=3, spherenet_out_emb_channels=256, split='scaffold', split_path='../datasets/chirality/d4_docking/rs/split0.npy', verbose=False)
Dataset: bbbp
Data: Data(edge_attr=[105842, 2], edge_index=[2, 105842], id=[2039], x=[49068, 2], y=[2039])
MoleculeDataset(2039)
split via scaffold
Data(edge_attr=[46, 2], edge_index=[2, 46], id=[1], x=[23, 2], y=[1])
GNN_graphpred(
(molecule_model): GNN(
(x_embedding1): Embedding(120, 300)
(x_embedding2): Embedding(3, 300)
(gnns): ModuleList(
(0): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(1): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(2): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(3): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
(4): GINConv(
(mlp): Sequential(
(0): Linear(in_features=300, out_features=600, bias=True)
(1): ReLU()
(2): Linear(in_features=600, out_features=300, bias=True)
)
(edge_embedding1): Embedding(6, 300)
(edge_embedding2): Embedding(3, 300)
)
)
(batch_norms): ModuleList(
(0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
)
(graph_pred_linear): Linear(in_features=300, out_features=1, bias=True)
)
Epoch: 1
Loss: 0.6675244412166323
train: 0.798060	val: 0.908662	test: 0.613908
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 2
Loss: 0.5412257530253408
train: 0.839230	val: 0.910669	test: 0.626543
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 3
Loss: 0.4570692119702433
train: 0.869778	val: 0.895815	test: 0.658179
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 4
Loss: 0.36871828898578846
train: 0.889394	val: 0.895012	test: 0.645158
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 5
Loss: 0.3288665547990955
train: 0.906103	val: 0.911774	test: 0.672068
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 6
Loss: 0.3041464927306857
train: 0.915821	val: 0.899127	test: 0.687211
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 7
Loss: 0.290777022689412
train: 0.925794	val: 0.914885	test: 0.689140
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 8
Loss: 0.2776652931335316
train: 0.936931	val: 0.919301	test: 0.679977
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 9
Loss: 0.2507999016805006
train: 0.939560	val: 0.917093	test: 0.688657
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 10
Loss: 0.2518702200243094
train: 0.946873	val: 0.926729	test: 0.683931
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 11
Loss: 0.244648693995168
train: 0.952516	val: 0.922112	test: 0.698688
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 12
Loss: 0.21896900950062206
train: 0.951549	val: 0.923417	test: 0.693962
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 13
Loss: 0.22213223501829185
train: 0.955765	val: 0.916491	test: 0.687307
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 14
Loss: 0.217187709618735
train: 0.955124	val: 0.917194	test: 0.676698
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 15
Loss: 0.21422232831221585
train: 0.963320	val: 0.916290	test: 0.686921
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 16
Loss: 0.20610474505249704
train: 0.959004	val: 0.917997	test: 0.689525
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 17
Loss: 0.20537858574296
train: 0.956452	val: 0.925926	test: 0.697049
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 18
Loss: 0.2024393450069584
train: 0.968072	val: 0.918800	test: 0.700521
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 19
Loss: 0.19036111143986603
train: 0.967745	val: 0.923417	test: 0.703993
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 20
Loss: 0.20805502531464068
train: 0.966546	val: 0.920305	test: 0.684221
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 21
Loss: 0.19131405239837376
train: 0.965908	val: 0.903142	test: 0.684896
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 22
Loss: 0.17310257106860671
train: 0.970300	val: 0.908160	test: 0.680459
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 23
Loss: 0.18082884810587635
train: 0.968724	val: 0.913179	test: 0.664448
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 24
Loss: 0.17675166895351954
train: 0.971446	val: 0.904848	test: 0.677855
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 25
Loss: 0.17885391793481434
train: 0.973491	val: 0.916792	test: 0.694348
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 26
Loss: 0.18424717371447658
train: 0.972237	val: 0.906153	test: 0.691744
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 27
Loss: 0.16916734293947627
train: 0.973693	val: 0.912476	test: 0.703221
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 28
Loss: 0.17441575337201834
train: 0.973592	val: 0.910168	test: 0.694444
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 29
Loss: 0.16051696527185538
train: 0.980709	val: 0.911974	test: 0.680073
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 30
Loss: 0.16801154862646067
train: 0.980772	val: 0.911974	test: 0.690490
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 31
Loss: 0.1561498663804115
train: 0.977204	val: 0.920305	test: 0.694637
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 32
Loss: 0.1561703466058839
train: 0.984005	val: 0.918197	test: 0.693383
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 33
Loss: 0.1517838118461576
train: 0.983057	val: 0.905149	test: 0.680845
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 34
Loss: 0.15297863304695633
train: 0.981827	val: 0.903643	test: 0.694059
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 35
Loss: 0.14593691331386097
train: 0.984681	val: 0.915086	test: 0.697434
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 36
Loss: 0.14507828491596633
train: 0.985282	val: 0.918800	test: 0.694155
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 37
Loss: 0.13919804104424133
train: 0.986968	val: 0.910067	test: 0.697820
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 38
Loss: 0.14361281499230144
train: 0.983833	val: 0.921208	test: 0.698881
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 39
Loss: 0.13996960262801622
train: 0.987184	val: 0.917495	test: 0.716917
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 40
Loss: 0.15128894220629854
train: 0.987013	val: 0.895313	test: 0.696663
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 41
Loss: 0.12931394844839025
train: 0.985296	val: 0.919502	test: 0.711420
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 42
Loss: 0.14436071910204634
train: 0.990487	val: 0.912878	test: 0.720775
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 43
Loss: 0.13036746640249705
train: 0.990721	val: 0.906855	test: 0.705729
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 44
Loss: 0.12457793270042336
train: 0.992461	val: 0.910870	test: 0.719811
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 45
Loss: 0.12969702730166202
train: 0.991482	val: 0.907959	test: 0.699942
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 46
Loss: 0.12398531077333277
train: 0.991570	val: 0.910870	test: 0.691937
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 47
Loss: 0.12081103577331931
train: 0.992210	val: 0.897822	test: 0.692419
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 48
Loss: 0.13038578717680152
train: 0.992915	val: 0.906052	test: 0.695505
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 49
Loss: 0.13261596131133274
train: 0.992482	val: 0.912777	test: 0.699846
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 50
Loss: 0.11517035976731305
train: 0.992411	val: 0.903242	test: 0.699846
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 51
Loss: 0.1233746569644295
train: 0.992874	val: 0.915989	test: 0.724923
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 52
Loss: 0.12440196860040834
train: 0.994851	val: 0.899528	test: 0.707465
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 53
Loss: 0.11881140445246181
train: 0.994393	val: 0.910268	test: 0.707176
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 54
Loss: 0.12890253064483284
train: 0.987941	val: 0.923216	test: 0.704765
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 55
Loss: 0.11225561882578197
train: 0.992413	val: 0.915487	test: 0.700039
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 56
Loss: 0.11692108738016611
train: 0.994950	val: 0.906755	test: 0.704475
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 57
Loss: 0.11148603315721317
train: 0.993365	val: 0.899829	test: 0.716242
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 58
Loss: 0.1256636946369634
train: 0.995018	val: 0.892302	test: 0.704572
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 59
Loss: 0.11473205547818524
train: 0.994560	val: 0.895714	test: 0.706887
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 60
Loss: 0.11383192375732995
train: 0.993952	val: 0.918498	test: 0.702353
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 61
Loss: 0.12039574238464715
train: 0.995555	val: 0.900130	test: 0.714892
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 62
Loss: 0.11633990530839709
train: 0.992334	val: 0.901034	test: 0.667052
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 63
Loss: 0.1049763185119458
train: 0.996280	val: 0.904948	test: 0.676601
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 64
Loss: 0.10555202978905684
train: 0.995438	val: 0.884573	test: 0.675829
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 65
Loss: 0.11738051063990705
train: 0.996168	val: 0.908461	test: 0.681617
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 66
Loss: 0.11375099401169807
train: 0.994220	val: 0.899930	test: 0.672454
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 67
Loss: 0.10858779879641126
train: 0.993834	val: 0.872026	test: 0.681327
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 68
Loss: 0.10428599174579863
train: 0.995713	val: 0.910168	test: 0.693866
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 69
Loss: 0.10699531334055719
train: 0.995197	val: 0.912476	test: 0.701775
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 70
Loss: 0.10596878094944386
train: 0.996563	val: 0.897722	test: 0.694444
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 71
Loss: 0.10117567690211625
train: 0.996959	val: 0.899328	test: 0.702450
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 72
Loss: 0.10167101985952853
train: 0.996551	val: 0.889993	test: 0.679977
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 73
Loss: 0.10350327992265537
train: 0.996844	val: 0.886881	test: 0.710552
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 74
Loss: 0.11321254684995927
train: 0.996011	val: 0.891900	test: 0.686632
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 75
Loss: 0.1046719545873566
train: 0.996556	val: 0.895614	test: 0.685475
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 76
Loss: 0.09682295592453154
train: 0.995819	val: 0.877948	test: 0.691840
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 77
Loss: 0.08521043156417306
train: 0.997381	val: 0.896617	test: 0.705826
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 78
Loss: 0.10180455648695688
train: 0.997091	val: 0.907056	test: 0.686632
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 79
Loss: 0.09650609305779737
train: 0.996495	val: 0.904045	test: 0.710841
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 80
Loss: 0.09925331470859125
train: 0.995344	val: 0.880458	test: 0.700810
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 81
Loss: 0.09113303443370104
train: 0.996970	val: 0.894911	test: 0.691069
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 82
Loss: 0.09799278480545741
train: 0.996793	val: 0.909867	test: 0.678048
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 83
Loss: 0.0885791826738536
train: 0.997256	val: 0.901937	test: 0.691744
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 84
Loss: 0.08944646247562109
train: 0.997129	val: 0.896718	test: 0.703607
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 85
Loss: 0.0866967770949678
train: 0.997160	val: 0.885777	test: 0.678241
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 86
Loss: 0.09441876478858695
train: 0.997676	val: 0.887383	test: 0.694444
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 87
Loss: 0.10403025039954117
train: 0.998105	val: 0.894309	test: 0.705054
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 88
Loss: 0.08656119441437546
train: 0.996489	val: 0.890796	test: 0.702160
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 89
Loss: 0.10327119557804787
train: 0.996887	val: 0.877145	test: 0.693866
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 90
Loss: 0.08222295755919233
train: 0.997297	val: 0.876945	test: 0.684317
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 91
Loss: 0.0815381238730439
train: 0.997756	val: 0.900933	test: 0.685185
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 92
Loss: 0.09705226254771744
train: 0.997380	val: 0.889893	test: 0.672550
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 93
Loss: 0.08800109474854244
train: 0.997422	val: 0.886681	test: 0.681327
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 94
Loss: 0.08582201893369211
train: 0.996464	val: 0.908060	test: 0.670235
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 95
Loss: 0.08313214978828874
train: 0.997634	val: 0.896216	test: 0.679688
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 96
Loss: 0.08042162676261067
train: 0.998315	val: 0.874837	test: 0.682870
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 97
Loss: 0.09609768486339905
train: 0.996785	val: 0.848439	test: 0.673900
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 98
Loss: 0.08037270824752271
train: 0.998056	val: 0.877346	test: 0.680652
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 99
Loss: 0.07334354557001589
train: 0.998130	val: 0.885978	test: 0.684606
acc train: 0.000000	val: 0.000000	test: 0.000000

Epoch: 100
Loss: 0.07075202223449244
train: 0.998127	val: 0.901134	test: 0.684896
acc train: 0.000000	val: 0.000000	test: 0.000000

best train: 0.946873	val: 0.926729	test: 0.683931
best ACC train: 0.000000	val: 0.000000	test: 0.000000
end
