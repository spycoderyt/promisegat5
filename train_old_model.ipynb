{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pickle\n",
    "import timeit\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "class ProteinProteinInteractionPrediction(nn.Module):\n",
    "    def __init__(self,mod_embed,prot_embed,dim=20,layer_gnn=2):\n",
    "        super(ProteinProteinInteractionPrediction, self).__init__()\n",
    "        self.prot_embed_fingerprint = nn.Embedding(n_fingerprint, dim)\n",
    "        self.mod_embed_fingerprint = nn.Embedding(nmod_fingerprint, dim)\n",
    "        self.mod_W_gnn = nn.ModuleList([nn.Linear(dim, dim) for _ in range(layer_gnn)])\n",
    "        self.prot_gnn = nn.ModuleList([nn.Linear(dim, dim) for _ in range(layer_gnn)])\n",
    "        self.prot_W1_attention = nn.Linear(dim, dim)\n",
    "        self.prot_W2_attention = nn.Linear(dim, dim)\n",
    "        self.prot_w = nn.Parameter(torch.zeros(dim))\n",
    "        self.W1_attention = nn.Linear(dim, dim)\n",
    "        self.W2_attention = nn.Linear(2*dim, dim)  # Modified to accept concatenated protein vector\n",
    "        self.w = nn.Parameter(torch.zeros(dim))\n",
    "        self.W_out = nn.Sequential(\n",
    "            nn.Linear(2*dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "        \n",
    "        self.mod_embed = mod_embed\n",
    "        self.prot_embed = prot_embed\n",
    "\n",
    "        self.rdkit_linear = nn.Linear(2048, dim)\n",
    "\n",
    "    def gnn(self, xs1, A1, type):\n",
    "        for i in range(layer_gnn):\n",
    "            if type == \"mod\":\n",
    "                hs1 = torch.relu(self.mod_W_gnn[i](xs1))\n",
    "            elif type == \"prot\":\n",
    "                hs1 = torch.relu(self.prot_gnn[i](xs1))\n",
    "            xs1 = torch.matmul(A1, hs1)\n",
    "\n",
    "        return xs1\n",
    "    \n",
    "    def mutual_attention(self, h1, h2):\n",
    "        x1 = self.W1_attention(h1)\n",
    "        x2 = self.W2_attention(h2)\n",
    "\n",
    "        m1 = x1.size()[0]\n",
    "        m2 = x2.size()[0]\n",
    "\n",
    "        c1 = x1.repeat(1, m2).view(m1, m2, dim)\n",
    "        c2 = x2.repeat(m1, 1).view(m1, m2, dim)\n",
    "\n",
    "        d = torch.tanh(c1 + c2)\n",
    "        alpha = torch.matmul(d, self.w).view(m1, m2)\n",
    "\n",
    "        b1 = torch.mean(alpha, 1)\n",
    "        p1 = torch.softmax(b1, 0)\n",
    "        s1 = torch.matmul(torch.t(x1), p1).view(-1, 1)\n",
    "\n",
    "        b2 = torch.mean(alpha, 0)\n",
    "        p2 = torch.softmax(b2, 0)\n",
    "        s2 = torch.matmul(torch.t(x2), p2).view(-1, 1)\n",
    "\n",
    "        return torch.cat((s1, s2), 0).view(1, -1), p1, p2\n",
    "    def prot_mutual_attention(self, h1, h2):\n",
    "        x1 = self.prot_W1_attention(h1)\n",
    "        x2 = self.prot_W2_attention(h2)\n",
    "\n",
    "        m1 = x1.size()[0]\n",
    "        m2 = x2.size()[0]\n",
    "\n",
    "        c1 = x1.repeat(1, m2).view(m1, m2, dim)\n",
    "        c2 = x2.repeat(m1, 1).view(m1, m2, dim)\n",
    "\n",
    "        d = torch.tanh(c1 + c2)\n",
    "        alpha = torch.matmul(d, self.prot_w).view(m1, m2)\n",
    "\n",
    "        b1 = torch.mean(alpha, 1)\n",
    "        p1 = torch.softmax(b1, 0)\n",
    "        s1 = torch.matmul(torch.t(x1), p1).view(-1, 1)\n",
    "\n",
    "        b2 = torch.mean(alpha, 0)\n",
    "        p2 = torch.softmax(b2, 0)\n",
    "        s2 = torch.matmul(torch.t(x2), p2).view(-1, 1)\n",
    "\n",
    "        return torch.cat((s1, s2), 0).view(1, -1), p1, p2\n",
    "\n",
    "    def forward(self, inputs, train = True):\n",
    "        fingerprints1, adjacency1, fingerprints2, adjacency2, fingerprints3, adjacency3, smiles = inputs\n",
    "\n",
    "        \"\"\"Protein vector with GNN.\"\"\"\n",
    "        x_fingerprints1 = self.mod_embed_fingerprint(fingerprints1)\n",
    "        x_fingerprints2 = self.prot_embed_fingerprint(fingerprints2)\n",
    "        x_fingerprints3 = self.prot_embed_fingerprint(fingerprints3)\n",
    "        if self.mod_embed == \"gnn\":\n",
    "            x_mod = self.gnn(x_fingerprints1, adjacency1, \"mod\")\n",
    "        elif self.mod_embed == \"rdkit\":\n",
    "            # Implement RDKit molecular fingerprinting\n",
    "            from rdkit import Chem\n",
    "            from rdkit.Chem import rdFingerprintGenerator\n",
    "\n",
    "            # Convert SMILES to RDKit mol object\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            # Generate Morgan fingerprint\n",
    "            morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048)\n",
    "            morgan_fp = morgan_gen.GetFingerprint(mol)\n",
    "            # Convert bit vector to PyTorch tensor\n",
    "            x_mod = torch.tensor([int(b) for b in morgan_fp.ToBitString()]).float().view(1, -1)\n",
    "            x_mod = self.rdkit_linear(x_mod)            \n",
    "        elif self.mod_embed == \"graphmvp\":\n",
    "            x_mod = self.graphmvp_embed(fingerprints1)\n",
    "        elif self.mod_embed == \"infograph\":\n",
    "            x_mod = self.infograph_embed(fingerprints1)\n",
    "\n",
    "        if self.prot_embed == \"gnn\":\n",
    "            x_protein2 = self.gnn(x_fingerprints2, adjacency2, \"prot\")\n",
    "            x_protein3 = self.gnn(x_fingerprints3, adjacency3, \"prot\")\n",
    "        # x_mod = N, dim\n",
    "\n",
    "        \"\"\"Concatenate protein vectors\"\"\"\n",
    "        x_proteins, p1, p2 = self.prot_mutual_attention(x_protein2, x_protein3)\n",
    "        # print(f\"shape of x_proteins: {x_proteins.shape}\")\n",
    "        # print(f\"shape of x_protein2: {x_protein2.shape}\")\n",
    "        # print(f\"shape of x_protein3: {x_protein3.shape}\")\n",
    "        \"\"\"Protein vector with mutual-attention.\"\"\"\n",
    "        y, p1, p2 = self.mutual_attention(x_mod, x_proteins)\n",
    "\n",
    "        z_interaction = self.W_out(y)\n",
    "        # ADD CHEMICAL FEATURE VECTOR HERE \n",
    "        return z_interaction, p1, p2\n",
    "\n",
    "    def __call__(self, data, train=True):\n",
    "        inputs, t_interaction = data[:-1], data[-1]\n",
    "        z_interaction, p1, p2 = self.forward(inputs, train)\n",
    "        if train:\n",
    "            loss = F.cross_entropy(z_interaction, t_interaction)\n",
    "            return loss\n",
    "        else:\n",
    "            z = F.softmax(z_interaction, 1).to(\"cpu\").data[0].numpy()\n",
    "            t = int(t_interaction.to(\"cpu\").data[0].numpy())\n",
    "            return z, t, p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, lr = 1e-4, train_size = 3000):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.train_size = train_size\n",
    "\n",
    "    def train(self, dataset):\n",
    "        self.model.train()  # Set model to training mode\n",
    "        sampling = random.choices(dataset, k=self.train_size)\n",
    "        loss_total = 0\n",
    "        for data in tqdm(sampling):\n",
    "            try:\n",
    "                mod, p1, p2, interaction, family = data\n",
    "                A1 = np.load(\n",
    "                        prot_data[prot_data['protein'] == p1].iloc[0]['adj_path'],\n",
    "                        allow_pickle=True\n",
    "                    )\n",
    "                A2 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p2].iloc[0]['adj_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "\n",
    "                P1 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p1].iloc[0]['fp_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                P2 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p2].iloc[0]['fp_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                mod_fp = np.load(\n",
    "                    mod_data[mod_data['inchikey'] == mod].iloc[0]['fp_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                mod_adj = np.load(\n",
    "                    mod_data[mod_data['inchikey'] == mod].iloc[0]['adj_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                smiles = mod_data[mod_data['inchikey'] == mod].iloc[0]['smiles']\n",
    "            except Exception as e:\n",
    "                # print(f\"failed for {e}\")\n",
    "                continue\n",
    "            protein1 = torch.LongTensor(P1.astype(np.float32))\n",
    "            protein2 = torch.LongTensor(P2.astype(np.float32))\n",
    "            adjacency1 = torch.FloatTensor(A1.astype(np.float32))\n",
    "            adjacency2 = torch.FloatTensor(A2.astype(np.float32))\n",
    "            mod_fp = torch.LongTensor(mod_fp.astype(np.float32))\n",
    "            mod_adj = torch.FloatTensor(mod_adj.astype(np.float32))\n",
    "            interaction = torch.LongTensor([interaction.astype(int)])\n",
    "\n",
    "            # comb = (protein1.to(device), adjacency1.to(device), protein2.to(device), adjacency2.to(device), interaction.to(device))\n",
    "            # with torch.no_grad():\n",
    "            # prot_loss, prot_embed = self.prot_model(comb, train=True)\n",
    "            \n",
    "            comb = (mod_fp.to(device), mod_adj.to(device), \n",
    "                    protein1.to(device), adjacency1.to(device), \n",
    "                    protein2.to(device), adjacency2.to(device), smiles,\n",
    "                    interaction.to(device))\n",
    "            loss = self.model(comb)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_total += loss.item()\n",
    "        return loss_total / len(sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Tester(object):\n",
    "    def __init__(self, model, test_size = 1000, wandb_project_name=False):\n",
    "        self.model = model\n",
    "        self.test_size = test_size\n",
    "\n",
    "        # Initialize wandb if a project name is provided\n",
    "        # if wandb_project_name:\n",
    "        #     wandb.init(project=wandb_project_name)\n",
    "        #     self.use_wandb = True\n",
    "        # else:\n",
    "        #     self.use_wandb = False\n",
    "\n",
    "    def test(self, dataset, epoch=None):\n",
    "        sampling = random.choices(dataset, k=self.test_size)\n",
    "        z_list, t_list = [], []\n",
    "        for data in tqdm(sampling):\n",
    "            try:\n",
    "                mod, p1, p2, interaction, _ = data\n",
    "                A1 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p1].iloc[0]['adj_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                A2 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p2].iloc[0]['adj_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                P1 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p1].iloc[0]['fp_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                P2 = np.load(\n",
    "                    prot_data[prot_data['protein'] == p2].iloc[0]['fp_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                mod_fp = np.load(\n",
    "                    mod_data[mod_data['inchikey'] == mod].iloc[0]['fp_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                mod_adj = np.load(\n",
    "                    mod_data[mod_data['inchikey'] == mod].iloc[0]['adj_path'],\n",
    "                    allow_pickle=True\n",
    "                )\n",
    "                smiles = mod_data[mod_data['inchikey'] == mod].iloc[0]['smiles']\n",
    "            except Exception as e:\n",
    "                # print(f\"failed for {mod}, {p1}, and {p2}: {e}\")\n",
    "                continue\n",
    "\n",
    "            protein1 = torch.LongTensor(P1.astype(np.float32))\n",
    "            protein2 = torch.LongTensor(P2.astype(np.float32))\n",
    "            adjacency1 = torch.FloatTensor(A1.astype(np.float32))\n",
    "            adjacency2 = torch.FloatTensor(A2.astype(np.float32))\n",
    "            mod_fp = torch.LongTensor(mod_fp.astype(np.float32))\n",
    "            mod_adj = torch.FloatTensor(mod_adj.astype(np.float32))\n",
    "            interaction = torch.LongTensor([interaction.astype(int)])\n",
    "\n",
    "            # comb = (protein1.to(device), adjacency1.to(device), protein2.to(device), adjacency2.to(device), interaction.to(device))\n",
    "            # with torch.no_grad():\n",
    "            # prot_loss, prot_embed = self.prot_model(comb, train=True)\n",
    "            \n",
    "            comb = (mod_fp.to(device), mod_adj.to(device), \n",
    "                    protein1.to(device), adjacency1.to(device), \n",
    "                    protein2.to(device), adjacency2.to(device), smiles,\n",
    "                    interaction.to(device))\n",
    "            z, _, _, _ = self.model(comb, train=False)\n",
    "            # print(z,interaction)\n",
    "            # print(z,torch.argmax(torch.FloatTensor(z)).item())\n",
    "            z_list.append(z)\n",
    "            t_list.append(interaction)\n",
    "\n",
    "        score_list, label_list = [], []\n",
    "        for z in z_list:\n",
    "            score_list.append(z[1].item())\n",
    "            label_list.append(torch.argmax(torch.FloatTensor(z)).item())\n",
    "\n",
    "        labels = np.array(label_list)\n",
    "        y_true = np.array([t.item() for t in t_list])\n",
    "        y_pred = np.array(score_list)\n",
    "\n",
    "        (\n",
    "            tp,\n",
    "            fp,\n",
    "            tn,\n",
    "            fn,\n",
    "            accuracy,\n",
    "            precision,\n",
    "            sensitivity,\n",
    "            recall,\n",
    "            specificity,\n",
    "            MCC,\n",
    "            F1_score,\n",
    "            Q9,\n",
    "            ppv,\n",
    "            npv,\n",
    "        ) = self.calculate_performace(len(sampling), labels, y_true)\n",
    "        roc_auc_val = roc_auc_score(y_true, y_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        auc_val = auc(fpr, tpr)\n",
    "\n",
    "        # Log results to wandb\n",
    "        # if self.use_wandb:\n",
    "        #     wandb.log({\n",
    "        #         \"Epoch\": epoch,\n",
    "        #         \"Accuracy\": accuracy,\n",
    "        #         \"Precision\": precision,\n",
    "        #         \"Recall\": recall,\n",
    "        #         \"Sensitivity\": sensitivity,\n",
    "        #         \"Specificity\": specificity,\n",
    "        #         \"MCC\": MCC,\n",
    "        #         \"F1 Score\": F1_score,\n",
    "        #         \"ROC AUC\": roc_auc_val,\n",
    "        #         \"AUC\": auc_val,\n",
    "        #         \"TP\": tp,\n",
    "        #         \"FP\": fp,\n",
    "        #         \"TN\": tn,\n",
    "        #         \"FN\": fn,\n",
    "        #         \"PPV\": ppv,\n",
    "        #         \"NPV\": npv,\n",
    "        #     })\n",
    "\n",
    "        return (\n",
    "            accuracy,\n",
    "            precision,\n",
    "            recall,\n",
    "            sensitivity,\n",
    "            specificity,\n",
    "            MCC,\n",
    "            F1_score,\n",
    "            roc_auc_val,\n",
    "            auc_val,\n",
    "            Q9,\n",
    "            ppv,\n",
    "            npv,\n",
    "            tp,\n",
    "            fp,\n",
    "            tn,\n",
    "            fn,\n",
    "        )\n",
    "\n",
    "    def result(\n",
    "        self,\n",
    "        epoch,\n",
    "        time,\n",
    "        loss,\n",
    "        accuracy,\n",
    "        precision,\n",
    "        recall,\n",
    "        sensitivity,\n",
    "        specificity,\n",
    "        MCC,\n",
    "        F1_score,\n",
    "        roc_auc_val,\n",
    "        auc_val,\n",
    "        Q9,\n",
    "        ppv,\n",
    "        npv,\n",
    "        tp,\n",
    "        fp,\n",
    "        tn,\n",
    "        fn,\n",
    "        file_name,\n",
    "    ):\n",
    "        import os\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "\n",
    "        # Open the file in append mode, creating it if it doesn't exist\n",
    "        with open(file_name, \"a+\") as f:\n",
    "            result = map(\n",
    "                str,\n",
    "                [\n",
    "                    epoch,\n",
    "                    time,\n",
    "                    loss,\n",
    "                    accuracy,\n",
    "                    precision,\n",
    "                    recall,\n",
    "                    sensitivity,\n",
    "                    specificity,\n",
    "                    MCC,\n",
    "                    F1_score,\n",
    "                    roc_auc_val,\n",
    "                    auc_val,\n",
    "                    Q9,\n",
    "                    ppv,\n",
    "                    npv,\n",
    "                    tp,\n",
    "                    fp,\n",
    "                    tn,\n",
    "                    fn,\n",
    "                ],\n",
    "            )\n",
    "            f.write(\"\\t\".join(result) + \"\\n\")\n",
    "\n",
    "    def calculate_performace(self, test_num, pred_y, labels):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        test_num = len(pred_y)\n",
    "        for index in range(test_num):\n",
    "            if labels[index] == 1:\n",
    "                if labels[index] == pred_y[index]:\n",
    "                    tp = tp + 1\n",
    "                else:\n",
    "                    fn = fn + 1\n",
    "            else:\n",
    "                if labels[index] == pred_y[index]:\n",
    "                    tn = tn + 1\n",
    "                else:\n",
    "                    fp = fp + 1\n",
    "\n",
    "        if (tp + fn) == 0:\n",
    "            q9 = float(tn - fp) / (tn + fp + 1e-06)\n",
    "        if (tn + fp) == 0:\n",
    "            q9 = float(tp - fn) / (tp + fn + 1e-06)\n",
    "        if (tp + fn) != 0 and (tn + fp) != 0:\n",
    "            q9 = 1 - float(np.sqrt(2)) * np.sqrt(float(fn * fn) / ((tp + fn) * (tp + fn)) + float(fp * fp) / ((tn + fp) * (tn + fp)))\n",
    "\n",
    "        Q9 = (float)(1 + q9) / 2\n",
    "        accuracy = float(tp + tn) / test_num\n",
    "        precision = float(tp) / (tp + fp + 1e-06)\n",
    "        sensitivity = float(tp) / (tp + fn + 1e-06)\n",
    "        recall = float(tp) / (tp + fn + 1e-06)\n",
    "        specificity = float(tn) / (tn + fp + 1e-06)\n",
    "        ppv = float(tp) / (tp + fp + 1e-06)\n",
    "        npv = float(tn) / (tn + fn + 1e-06)\n",
    "        F1_score = float(2 * tp) / (2 * tp + fp + fn + 1e-06)\n",
    "        MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "\n",
    "        return tp, fp, tn, fn, accuracy, precision, sensitivity, recall, specificity, MCC, F1_score, Q9, ppv, npv\n",
    "\n",
    "    def save_model(self, model, file_name):\n",
    "        torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000]) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "z = torch.FloatTensor(np.array([0.1, 0.2], dtype=np.float32))\n",
    "print(z, torch.argmax(z,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data\n",
    "prot_data = pd.read_csv(\"prot_data.csv\")\n",
    "mod_data = pd.read_csv(\"mod_data.csv\")\n",
    "train_data = pd.read_csv(\"interaction_data.csv\")\n",
    "examples = np.array(train_data.values.tolist())\n",
    "# examples = np.array(random.choices(examples_all, k=500))\n",
    "\n",
    "# setup folders\n",
    "prot_fp_folder = \"protein_fingerprints\"\n",
    "mod_fp_folder = \"mod_fingerprints\"\n",
    "prot_fp_dict = np.load(\"protein_fingerprints/prot_fingerprint_dict.pickle\",allow_pickle=True)\n",
    "mod_fp_dict = np.load(\"mod_fingerprints/mod_fingerprint_dict.pickle\",allow_pickle=True)\n",
    "\n",
    "\n",
    "n_fingerprint = len(prot_fp_dict) + 100\n",
    "nmod_fingerprint = len(mod_fp_dict) + 100\n",
    "\n",
    "\n",
    "### Hyperparameters ###\n",
    "\n",
    "radius         = 1\n",
    "dim        = 100\n",
    "layer_gnn      = 2\n",
    "lr             = 1e-4\n",
    "lr_decay       = 0.5\n",
    "decay_interval = 10\n",
    "iteration      = 30\n",
    "\n",
    "import wandb\n",
    "import timeit\n",
    "import torch\n",
    "\n",
    "fold_count = 2\n",
    "### Check if GPU is available ###\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "### Define k-folds ###\n",
    "num_kfolds = 5\n",
    "kfold      = KFold(n_splits=num_kfolds, shuffle=True, random_state=1)  # Updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db3c01e87bc44f19922227c3ea63b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01113756018878323, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gino/promisegat4/wandb/run-20240903_064957-3nxydhwq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/spycoderyt/promisegat4/runs/3nxydhwq' target=\"_blank\">light-snowball-36</a></strong> to <a href='https://wandb.ai/spycoderyt/promisegat4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/spycoderyt/promisegat4' target=\"_blank\">https://wandb.ai/spycoderyt/promisegat4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/spycoderyt/promisegat4/runs/3nxydhwq' target=\"_blank\">https://wandb.ai/spycoderyt/promisegat4/runs/3nxydhwq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:09.007714, resuming normal operation.\n",
      "100%|██████████| 3000/3000 [33:11<00:00,  1.51it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.5844416664093732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:47<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Accuracy: 0.5863636363636363\n",
      "Precision: 0.4683098575059512\n",
      "Recall: 0.38439306247285243\n",
      "Sensitivity: 0.38439306247285243\n",
      "Specificity: 0.7172284630763512\n",
      "MCC: 0.10617251348402833\n",
      "F1-score: 0.4222222215520282\n",
      "ROC-AUC: 0.5902448528934208\n",
      "AUC: 0.5902448528934208\n",
      "Q9: 0.5209740917767137\n",
      "PPV: 0.4683098575059512\n",
      "NPV: 0.6426174485862124\n",
      "TP: 133\n",
      "FP: 151\n",
      "TN: 383\n",
      "FN: 213\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [18:23<00:00,  2.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.5729459016571442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:27<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Accuracy: 0.6064073226544623\n",
      "Precision: 0.5294117632903429\n",
      "Recall: 0.5409836050792798\n",
      "Sensitivity: 0.5409836050792798\n",
      "Specificity: 0.6535433058001116\n",
      "MCC: 0.19396853778557266\n",
      "F1-score: 0.5351351344119796\n",
      "ROC-AUC: 0.6510826771653544\n",
      "AUC: 0.6510826771653544\n",
      "Q9: 0.5933500955898594\n",
      "PPV: 0.5294117632903429\n",
      "NPV: 0.663999998672\n",
      "TP: 198\n",
      "FP: 176\n",
      "TN: 332\n",
      "FN: 168\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:15<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.5336938950838521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:44<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Accuracy: 0.6472564389697648\n",
      "Precision: 0.576271181557024\n",
      "Recall: 0.20420420359097838\n",
      "Sensitivity: 0.20420420359097838\n",
      "Specificity: 0.9107142840880103\n",
      "MCC: 0.16410211782088463\n",
      "F1-score: 0.30155210576152525\n",
      "ROC-AUC: 0.7429617117117118\n",
      "AUC: 0.7429617117117118\n",
      "Q9: 0.43375672746522886\n",
      "PPV: 0.576271181557024\n",
      "NPV: 0.6580645152799167\n",
      "TP: 68\n",
      "FP: 50\n",
      "TN: 510\n",
      "FN: 265\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:33<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.47699855659335544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Accuracy: 0.6938775510204082\n",
      "Precision: 0.5967741921733314\n",
      "Recall: 0.7316384160123208\n",
      "Sensitivity: 0.7316384160123208\n",
      "Specificity: 0.6685606047943928\n",
      "MCC: 0.3923835082400499\n",
      "F1-score: 0.6573604052571569\n",
      "ROC-AUC: 0.7559386235233693\n",
      "AUC: 0.7559386235233693\n",
      "Q9: 0.698445684406604\n",
      "PPV: 0.5967741921733314\n",
      "NPV: 0.7879464268126196\n",
      "TP: 259\n",
      "FP: 175\n",
      "TN: 353\n",
      "FN: 95\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:10<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.4298171651582234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:30<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Accuracy: 0.7642369020501139\n",
      "Precision: 0.693820222770168\n",
      "Recall: 0.715942026910313\n",
      "Sensitivity: 0.715942026910313\n",
      "Specificity: 0.7954971842485982\n",
      "MCC: 0.5087529332143521\n",
      "F1-score: 0.7047075596223858\n",
      "ROC-AUC: 0.8367349158441418\n",
      "AUC: 0.8367349158441418\n",
      "Q9: 0.7525021899726329\n",
      "PPV: 0.693820222770168\n",
      "NPV: 0.8122605348424128\n",
      "TP: 247\n",
      "FP: 109\n",
      "TN: 424\n",
      "FN: 98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:16<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.39243348833860364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:29<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Accuracy: 0.7839643652561247\n",
      "Precision: 0.7854984870528746\n",
      "Recall: 0.6788511731622685\n",
      "Sensitivity: 0.6788511731622685\n",
      "Specificity: 0.8621359206560467\n",
      "MCC: 0.5546057684037559\n",
      "F1-score: 0.7282913155065948\n",
      "ROC-AUC: 0.8465512433775255\n",
      "AUC: 0.8465512433775255\n",
      "Q9: 0.7528734415804534\n",
      "PPV: 0.7854984870528746\n",
      "NPV: 0.7830687816877094\n",
      "TP: 260\n",
      "FP: 71\n",
      "TN: 444\n",
      "FN: 123\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:39<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.3582613538142323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:22<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "Accuracy: 0.8379888268156425\n",
      "Precision: 0.7983193254949038\n",
      "Recall: 0.796089383251147\n",
      "Sensitivity: 0.796089383251147\n",
      "Specificity: 0.8659217860969799\n",
      "MCC: 0.6623213116400156\n",
      "F1-score: 0.7972027960878283\n",
      "ROC-AUC: 0.8950641365750133\n",
      "AUC: 0.8950641365750133\n",
      "Q9: 0.8274362353693029\n",
      "PPV: 0.7983193254949038\n",
      "NPV: 0.8643122660514642\n",
      "TP: 285\n",
      "FP: 72\n",
      "TN: 465\n",
      "FN: 73\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [08:51<00:00,  5.64it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.3190947156609873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [20:24<00:00,  1.22s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "Accuracy: 0.813692480359147\n",
      "Precision: 0.816513758970906\n",
      "Recall: 0.7158176924508909\n",
      "Sensitivity: 0.7158176924508909\n",
      "Specificity: 0.8841698824629926\n",
      "MCC: 0.6141127678777935\n",
      "F1-score: 0.762857141767347\n",
      "ROC-AUC: 0.8881369880029398\n",
      "AUC: 0.8881369880029398\n",
      "Q9: 0.7830020753942379\n",
      "PPV: 0.816513758970906\n",
      "NPV: 0.8120567361488356\n",
      "TP: 267\n",
      "FP: 60\n",
      "TN: 458\n",
      "FN: 106\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [10:34<00:00,  4.73it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.297444284398747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:54<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "Accuracy: 0.8223234624145785\n",
      "Precision: 0.8356164354944643\n",
      "Recall: 0.6931818162125517\n",
      "Sensitivity: 0.6931818162125517\n",
      "Specificity: 0.9087452454206364\n",
      "MCC: 0.6261347993085237\n",
      "F1-score: 0.7577639739786274\n",
      "ROC-AUC: 0.9075732371240925\n",
      "AUC: 0.9075732371240925\n",
      "Q9: 0.7736542173882605\n",
      "PPV: 0.8356164354944643\n",
      "NPV: 0.8156996573110927\n",
      "TP: 244\n",
      "FP: 48\n",
      "TN: 478\n",
      "FN: 108\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [07:27<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.2821158175678046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:46<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "Accuracy: 0.8604910714285714\n",
      "Precision: 0.8266666639111111\n",
      "Recall: 0.7725856673751226\n",
      "Sensitivity: 0.7725856673751226\n",
      "Specificity: 0.9095652158094518\n",
      "MCC: 0.6930796215942083\n",
      "F1-score: 0.7987117539473241\n",
      "ROC-AUC: 0.9190898008939457\n",
      "AUC: 0.9190898008939457\n",
      "Q9: 0.8269454890879542\n",
      "PPV: 0.8266666639111111\n",
      "NPV: 0.8775167770511464\n",
      "TP: 248\n",
      "FP: 52\n",
      "TN: 523\n",
      "FN: 73\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:56<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.26547160598860947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:32<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Accuracy: 0.8597081930415263\n",
      "Precision: 0.8553459092599185\n",
      "Recall: 0.7749287727210007\n",
      "Sensitivity: 0.7749287727210007\n",
      "Specificity: 0.9148148131207133\n",
      "MCC: 0.7034726869109025\n",
      "F1-score: 0.8131539599205472\n",
      "ROC-AUC: 0.9270391474095179\n",
      "AUC: 0.9270391474095179\n",
      "Q9: 0.8298330641251122\n",
      "PPV: 0.8553459092599185\n",
      "NPV: 0.8621291433470696\n",
      "TP: 272\n",
      "FP: 46\n",
      "TN: 494\n",
      "FN: 79\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [07:32<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.2583987712395542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:08<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n",
      "Accuracy: 0.8660022148394242\n",
      "Precision: 0.8529411739619377\n",
      "Recall: 0.8033240974977172\n",
      "Sensitivity: 0.8033240974977172\n",
      "Specificity: 0.9077490758159611\n",
      "MCC: 0.7189089410630818\n",
      "F1-score: 0.827389442471627\n",
      "ROC-AUC: 0.9358613322975334\n",
      "AUC: 0.9358613322975334\n",
      "Q9: 0.8463906863930856\n",
      "PPV: 0.8529411739619377\n",
      "NPV: 0.8738898741138723\n",
      "TP: 290\n",
      "FP: 50\n",
      "TN: 492\n",
      "FN: 71\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [07:05<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.24787745296370406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:42<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n",
      "Accuracy: 0.8231981981981982\n",
      "Precision: 0.8544303770429419\n",
      "Recall: 0.7086614154628309\n",
      "Sensitivity: 0.7086614154628309\n",
      "Specificity: 0.9092702151690922\n",
      "MCC: 0.6388006373562447\n",
      "F1-score: 0.7747489228482799\n",
      "ROC-AUC: 0.9055687565681508\n",
      "AUC: 0.9055687565681508\n",
      "Q9: 0.7842338496353438\n",
      "PPV: 0.8544303770429419\n",
      "NPV: 0.8059440545350628\n",
      "TP: 270\n",
      "FP: 46\n",
      "TN: 461\n",
      "FN: 111\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:58<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.24497829783441125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:32<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "Accuracy: 0.8491620111731844\n",
      "Precision: 0.8338278907008074\n",
      "Recall: 0.7805555533873457\n",
      "Sensitivity: 0.7805555533873457\n",
      "Specificity: 0.8953271011302297\n",
      "MCC: 0.6840177868651884\n",
      "F1-score: 0.8063127678532098\n",
      "ROC-AUC: 0.9207502596053997\n",
      "AUC: 0.9207502596053997\n",
      "Q9: 0.8280810080226881\n",
      "PPV: 0.8338278907008074\n",
      "NPV: 0.858422937529708\n",
      "TP: 281\n",
      "FP: 56\n",
      "TN: 479\n",
      "FN: 79\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [15:50<00:00,  3.16it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.2156337700015431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:27<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n",
      "Accuracy: 0.8571428571428571\n",
      "Precision: 0.8571428546938775\n",
      "Recall: 0.7936507915511883\n",
      "Sensitivity: 0.7936507915511883\n",
      "Specificity: 0.9034749017307434\n",
      "MCC: 0.7056535456712133\n",
      "F1-score: 0.8241758230437145\n",
      "ROC-AUC: 0.9358542215685073\n",
      "AUC: 0.9358542215685073\n",
      "Q9: 0.8389144804457481\n",
      "PPV: 0.8571428546938775\n",
      "NPV: 0.8571428555729984\n",
      "TP: 300\n",
      "FP: 50\n",
      "TN: 468\n",
      "FN: 78\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:27<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with loss 0.2211919988439531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:26<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n",
      "Accuracy: 0.8509454949944383\n",
      "Precision: 0.8631921795987225\n",
      "Recall: 0.7422969166882439\n",
      "Sensitivity: 0.7422969166882439\n",
      "Specificity: 0.9225092233902044\n",
      "MCC: 0.6859599098312033\n",
      "F1-score: 0.7981927698822399\n",
      "ROC-AUC: 0.9298143611688219\n",
      "AUC: 0.9298143611688219\n",
      "Q9: 0.8097163981414526\n",
      "PPV: 0.8631921795987225\n",
      "NPV: 0.8445945931679145\n",
      "TP: 265\n",
      "FP: 42\n",
      "TN: 500\n",
      "FN: 92\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1485/3000 [03:23<03:15,  7.76it/s]"
     ]
    }
   ],
   "source": [
    "train_size = 3000\n",
    "test_size = 1000\n",
    "log_wandb = True\n",
    "\n",
    "for train, test in kfold.split(examples):\n",
    "    dataset_train = examples[train]  # mod, prot1, prot2, int, int_family\n",
    "    dataset_test = examples[test]\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    model = ProteinProteinInteractionPrediction(dim=dim, layer_gnn=layer_gnn, mod_embed=\"rdkit\", prot_embed = \"gnn\").to(device)\n",
    "    trainer = Trainer(model, lr = lr, train_size=train_size, )\n",
    "    file_model = \"ppim/model/\" + \"rdkit_fold_\" + str(fold_count)\n",
    "    file_result = \"ppim/result/\" + \"rdkit_fold_\" + str(fold_count) + \".txt\"\n",
    "    if log_wandb:\n",
    "        wandb.init(project=\"promisegat4\")\n",
    "        # Log file paths to wandb\n",
    "        wandb.config.update({\n",
    "            \"fold\": fold_count,\n",
    "            \"model_path\": file_model,\n",
    "            \"result_path\": file_result,\n",
    "            \"protein_embed\": \"gcn\",\n",
    "            \"mod_embed\": \"gcn\",\n",
    "            \"radius\": radius,\n",
    "            \"dim\": dim,\n",
    "            \"layer_gnn\": layer_gnn,\n",
    "            \"lr\": lr,\n",
    "            \"lr_decay\": lr_decay,\n",
    "            \"decay_interval\": decay_interval,\n",
    "            \"iteration\": iteration\n",
    "        })\n",
    "\n",
    "    for epoch in range(iteration):\n",
    "        if (epoch + 1) % decay_interval == 0:\n",
    "            trainer.optimizer.param_groups[0][\"lr\"] *= lr_decay\n",
    "\n",
    "        loss = trainer.train(dataset_train)\n",
    "        print(f\"finished with loss {loss}\")\n",
    "\n",
    "        # Log training loss and GPU usage to wandb\n",
    "        gpu_usage = torch.cuda.memory_allocated(device=device) / 1024 ** 3  # in GB\n",
    "        if log_wandb:\n",
    "            wandb.log({\"epoch\": epoch, \"loss\": loss, \"gpu_usage_gb\": gpu_usage, \"fold\": fold_count})\n",
    "\n",
    "        tester = Tester(model, test_size = test_size)\n",
    "        (\n",
    "            accuracy,\n",
    "            precision,\n",
    "            recall,\n",
    "            sensitivity,\n",
    "            specificity,\n",
    "            MCC,\n",
    "            F1_score,\n",
    "            roc_auc_val,\n",
    "            auc_val,\n",
    "            Q9,\n",
    "            ppv,\n",
    "            npv,\n",
    "            tp,\n",
    "            fp,\n",
    "            tn,\n",
    "            fn,\n",
    "        ) = tester.test(dataset_test, epoch=epoch)\n",
    "        end = timeit.default_timer()\n",
    "        time = end - start\n",
    "\n",
    "        # Log results to wandb\n",
    "        if log_wandb:\n",
    "            wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"time\": time,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"specificity\": specificity,\n",
    "            \"MCC\": MCC,\n",
    "            \"F1_score\": F1_score,\n",
    "            \"ROC_AUC\": roc_auc_val,\n",
    "            \"AUC\": auc_val,\n",
    "            \"Q9\": Q9,\n",
    "            \"PPV\": ppv,\n",
    "            \"NPV\": npv,\n",
    "            \"TP\": tp,\n",
    "            \"FP\": fp,\n",
    "            \"TN\": tn,\n",
    "            \"FN\": fn,\n",
    "            \"fold\": fold_count\n",
    "        })\n",
    "\n",
    "        tester.result(\n",
    "            epoch,\n",
    "            time,\n",
    "            loss,\n",
    "            accuracy,\n",
    "            precision,\n",
    "            recall,\n",
    "            sensitivity,\n",
    "            specificity,\n",
    "            MCC,\n",
    "            F1_score,\n",
    "            roc_auc_val,\n",
    "            auc_val,\n",
    "            Q9,\n",
    "            ppv,\n",
    "            npv,\n",
    "            tp,\n",
    "            fp,\n",
    "            tn,\n",
    "            fn,\n",
    "            file_result,\n",
    "        )\n",
    "        tester.save_model(model, file_model)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        print(\"Accuracy: \" + str(accuracy))\n",
    "        print(\"Precision: \" + str(precision))\n",
    "        print(\"Recall: \" + str(recall))\n",
    "        print(\"Sensitivity: \" + str(sensitivity))\n",
    "        print(\"Specificity: \" + str(specificity))\n",
    "        print(\"MCC: \" + str(MCC))\n",
    "        print(\"F1-score: \" + str(F1_score))\n",
    "        print(\"ROC-AUC: \" + str(roc_auc_val))\n",
    "        print(\"AUC: \" + str(auc_val))\n",
    "        print(\"Q9: \" + str(Q9))\n",
    "        print(\"PPV: \" + str(ppv))\n",
    "        print(\"NPV: \" + str(npv))\n",
    "        print(\"TP: \" + str(tp))\n",
    "        print(\"FP: \" + str(fp))\n",
    "        print(\"TN: \" + str(tn))\n",
    "        print(\"FN: \" + str(fn))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        torch.manual_seed(1234)\n",
    "    if log_wandb:\n",
    "        wandb.finish()\n",
    "    fold_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promisegat4",
   "language": "python",
   "name": "promisegat4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
